#!/usr/bin/env python
import rospy
from sensor_msgs.msg import Image
from cv_bridge import CvBridge
from turtlebot3_detection import load_model, inference
from std_msgs.msg import Float32MultiArray

class Inference():
    def __init__(self) -> None:
        input_topic = rospy.get_param("~input_topic")
        output_topic = rospy.get_param("~output_topic")
        bbox_topic = rospy.get_param("~bbox_topic")
        model_path = rospy.get_param("~model_path")
        self.bridge = CvBridge()
        self.model = load_model(model_path)
        self.image_sub = rospy.Subscriber(input_topic, Image, queue_size=1, callback=self.inference_pipeline_callback)
        self.inference_pub = rospy.Publisher(output_topic, Image, queue_size=1)
        self.bbox_pub = rospy.Publisher(bbox_topic, Float32MultiArray, queue_size=1)

    def inference_pipeline_callback(self, msg: Image) -> None:
        # Step 1: Convert from sensor_msgs Image to opencv numpy image
        image = self.bridge.imgmsg_to_cv2(msg, desired_encoding='passthrough')
        # Step 2: Get the bounding boxes with maximum detection=1 and inferred image using the function "inference"
        bounding_boxes, inferred_image = inference(self.model, image, max_det=1)
        # Step 3: if there is an object, Take the first 4 element and put it on the Float32MultiArray 
        bbox_array = Float32MultiArray()
        if bounding_boxes:
            bbox_array.data = bounding_boxes[0][:4]
        # Step 4: Publish the bounding box array and convert the inferred image back to sensor msgs
        self.bbox_pub.publish(bbox_array)
        img_msg = self.bridge.cv2_to_imgmsg(inferred_image, encoding="bgr8")
        self.inference_pub.publish(img_msg)

if __name__ == "__main__":
    rospy.init_node("inference_test")
    inf = Inference()
    rospy.spin()